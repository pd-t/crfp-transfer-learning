{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50973d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 50 not upgraded.\n",
      "Need to get 335 kB of archives.\n",
      "After this operation, 1231 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 zip amd64 3.0-11build1 [167 kB]\n",
      "Fetched 335 kB in 1s (480 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 25583 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-25ubuntu1.1_amd64.deb ...\n",
      "Unpacking unzip (6.0-25ubuntu1.1) ...\n",
      "Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-11build1_amd64.deb ...\n",
      "Unpacking zip (3.0-11build1) ...\n",
      "Setting up unzip (6.0-25ubuntu1.1) ...\n",
      "Setting up zip (3.0-11build1) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "#install unzip in notebook\n",
    "!sudo apt-get install -y unzip zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d9198b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ray/anaconda3/lib/python3.8/site-packages (1.4.8)\n",
      "Requirement already satisfied: datasets in /home/ray/anaconda3/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Collecting botocore<1.9.0,>=1.8.0\n",
      "  Downloading botocore-1.8.50-py2.py3-none-any.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10\n",
      "  Downloading s3transfer-0.1.13-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: packaging in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (4.63.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: multiprocess in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: xxhash in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from botocore<1.9.0,>=1.8.0->boto3) (2.8.2)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/ray/anaconda3/lib/python3.8/site-packages (from botocore<1.9.0,>=1.8.0->boto3) (0.16)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.9.0,>=1.8.0->boto3) (1.13.0)\n",
      "Installing collected packages: botocore, s3transfer\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.97\n",
      "    Uninstalling botocore-1.29.97:\n",
      "      Successfully uninstalled botocore-1.29.97\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.0\n",
      "    Uninstalling s3transfer-0.6.0:\n",
      "      Successfully uninstalled s3transfer-0.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 0.4.2 requires botocore>=1.12.91, but you have botocore 1.8.50 which is incompatible.\n",
      "awscli 1.27.97 requires botocore==1.29.97, but you have botocore 1.8.50 which is incompatible.\n",
      "awscli 1.27.97 requires s3transfer<0.7.0,>=0.6.0, but you have s3transfer 0.1.13 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.8.50 s3transfer-0.1.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445cfde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3', endpoint_url='https://storage.s3.mlops.wogra.com')\n",
    "bucket = s3.Bucket('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8b4a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.download_file('dlr/dataset_tapelegen.zip', 'data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2fc685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "   creating: data/dataset_tapelegen/\n",
      "  inflating: data/dataset_tapelegen/dataset_info.json  \n",
      "  inflating: data/dataset_tapelegen/data-00001-of-00003.arrow  \n",
      "  inflating: data/dataset_tapelegen/state.json  \n",
      "  inflating: data/dataset_tapelegen/data-00000-of-00003.arrow  \n",
      "  inflating: data/dataset_tapelegen/data-00002-of-00003.arrow  \n",
      " extracting: data/dataset_tapelegen/dataset_dict.json  \n",
      "   creating: data/dataset_tapelegen/train/\n",
      "  inflating: data/dataset_tapelegen/train/dataset_info.json  \n",
      "  inflating: data/dataset_tapelegen/train/data-00001-of-00003.arrow  \n",
      "  inflating: data/dataset_tapelegen/train/state.json  \n",
      "  inflating: data/dataset_tapelegen/train/data-00000-of-00003.arrow  \n",
      "  inflating: data/dataset_tapelegen/train/data-00002-of-00003.arrow  \n"
     ]
    }
   ],
   "source": [
    "# extreact zip file to data folder\n",
    "!rm -r data\n",
    "!unzip data.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8488732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ray/anaconda3/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: packaging in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: xxhash in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (4.63.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (2022.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: pandas in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.13.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2f48c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 73749\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset for images in the folders and use the folder name as label\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"data/dataset_tapelegen/\")\n",
    "\n",
    "# take random seed of examples from dataset\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec86baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "# remove all items from dataset with mean 0 but dont use remove rows which not exists as method\n",
    "import numpy as np\n",
    "clean_dataset = dataset.filter(lambda example: np.mean(example[\"image\"]) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc6bc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 72287\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb5199ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.26.1 in /home/ray/anaconda3/lib/python3.8/site-packages (4.26.1)\n",
      "Requirement already satisfied: evaluate in /home/ray/anaconda3/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (2023.3.22)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (0.13.3)\n",
      "Requirement already satisfied: filelock in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (3.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (21.3)\n",
      "Requirement already satisfied: requests in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (4.63.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from transformers==4.26.1) (5.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (2022.11.0)\n",
      "Requirement already satisfied: xxhash in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (2.12.0)\n",
      "Requirement already satisfied: pandas in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: responses<0.19 in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /home/ray/anaconda3/lib/python3.8/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (12.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/ray/anaconda3/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ray/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.26.1) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.26.1) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.26.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.26.1) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.26.1) (3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->evaluate) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ray/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.13.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.26.1 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f6fdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'height': 224, 'width': 224}\n",
      "[0.5, 0.5, 0.5]\n",
      "[0.5, 0.5, 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "feature_extractor = transformers.AutoFeatureExtractor.from_pretrained(\n",
    "    checkpoint\n",
    ")\n",
    "print(feature_extractor.size)\n",
    "print(feature_extractor.image_mean)\n",
    "print(feature_extractor.image_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b8f6624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'TiffImageFile' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m preprocess_transform \u001b[39m=\u001b[39m Preprocess()\n\u001b[1;32m     36\u001b[0m \u001b[39m# Apply the transforms and save the preprocessed dataset to disk\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m preprocessed_dataset \u001b[39m=\u001b[39m clean_dataset\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;49;00m example: preprocess_transform(example), with_indices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py:578\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    577\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    579\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    580\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    581\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py:543\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    537\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    538\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    539\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    540\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    541\u001b[0m }\n\u001b[1;32m    542\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    544\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    545\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3065\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3066\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3067\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3068\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3071\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3072\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3073\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3074\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3075\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py:3427\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3425\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3426\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3427\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   3428\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   3429\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py:3330\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3328\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3329\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3330\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3332\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3333\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3334\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[50], line 37\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     34\u001b[0m preprocess_transform \u001b[39m=\u001b[39m Preprocess()\n\u001b[1;32m     36\u001b[0m \u001b[39m# Apply the transforms and save the preprocessed dataset to disk\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m preprocessed_dataset \u001b[39m=\u001b[39m clean_dataset\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m example: preprocess_transform(example), with_indices\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[50], line 26\u001b[0m, in \u001b[0;36mPreprocess.__call__\u001b[0;34m(self, example_batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, example_batch):\n\u001b[0;32m---> 26\u001b[0m     example_batch[\u001b[39m\"\u001b[39m\u001b[39mpixel_values\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms(img) \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m example_batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m     ]\n\u001b[1;32m     29\u001b[0m     \u001b[39mdel\u001b[39;00m example_batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m example_batch\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TiffImageFile' object is not iterable"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(image):\n",
    "    # convert image to tensor\n",
    "    tensor = transforms.ToTensor()(image)\n",
    "    tensor = tensor - np.mean(tensor.numpy()) + 128\n",
    "    tensor[tensor < 0] = 0\n",
    "    tensor[tensor > 255] = 255\n",
    "    tensor = tensor / 255\n",
    "    # repeat the tensor two ore times to get 3 channels and use the repeat function\n",
    "    tensor = tensor.repeat(3, 1, 1)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        self.transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Lambda(preprocess),\n",
    "                transforms.CenterCrop(224),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, example_batch):\n",
    "        example_batch[\"pixel_values\"] = [\n",
    "            self.transforms(img) for img in example_batch[\"image\"]\n",
    "        ]\n",
    "        del example_batch[\"image\"]\n",
    "        return example_batch\n",
    "    \n",
    "preprocessed_dataset = clean_dataset.with_transform(Preprocess())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08c4f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset = []\n",
    "for example in preprocessed_dataset:\n",
    "    save_dataset.append(example)\n",
    "\n",
    "# Convert the new dataset to a datasets.Dataset object\n",
    "new_dataset = Dataset.from_dict(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827d3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = clean_dataset.features[\"label\"].names\n",
    "\n",
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94b74da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'g', '1': 'n', '2': 'o'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f061fc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'g': '0', 'n': '1', 'o': '2'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deeab044",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelids = [int(id) for id in id2label.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ad6a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01fe603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 14*16\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_tapelegen_model\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca67abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2238dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c864cc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "filtered_datasets = [preprocessed_dataset.filter(lambda example: example[\"label\"] == labelid, batch_size=1024) for labelid in labelids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a372664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 8707\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edc83498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3248"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the minimum number of examples in the dataset with respect to the label\n",
    "min_examples = min(data.num_rows for data in filtered_datasets)\n",
    "min_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a17ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "weighted_dataset = concatenate_datasets(\n",
    "    [\n",
    "        fd.shuffle(seed=42).select(range(min_examples)) for fd in filtered_datasets\n",
    "    ]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a66fd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_dataset.num_rows - 3*min_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b109ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% train, 10% test + validation\n",
    "split_one = weighted_dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "463f18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 10% test + valid in half test, half valid\n",
    "split_two = split_one['test'].train_test_split(test_size=0.5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcfec18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 7795\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 974\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 975\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "train_test_valid_dataset = DatasetDict({\n",
    "    \"train\": split_one[\"train\"],\n",
    "    \"validate\": split_two[\"train\"],\n",
    "    \"test\": split_two[\"test\"]})\n",
    "train_test_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ff401f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dfae547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_test_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_test_valid_dataset[\"validate\"],\n",
    "    tokenizer=image_processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "846d90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7795\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 224\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2688\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 30\n",
      "  Number of trainable parameters = 85800963\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4/30 00:21 < 04:33, 0.10 it/s, Epoch 1/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/2 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-3\n",
      "Configuration saved in my_tapelegen_model/checkpoint-3/config.json\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-3\n",
      "Configuration saved in my_tapelegen_model/checkpoint-3/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-3/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-3/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-6\n",
      "Configuration saved in my_tapelegen_model/checkpoint-6/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-6/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-6/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-9\n",
      "Configuration saved in my_tapelegen_model/checkpoint-9/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-9/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-9/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-12\n",
      "Configuration saved in my_tapelegen_model/checkpoint-12/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-12/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-12/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-15\n",
      "Configuration saved in my_tapelegen_model/checkpoint-15/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-15/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-15/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-18\n",
      "Configuration saved in my_tapelegen_model/checkpoint-18/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-18/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-18/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-21\n",
      "Configuration saved in my_tapelegen_model/checkpoint-21/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-21/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-21/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-24\n",
      "Configuration saved in my_tapelegen_model/checkpoint-24/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-24/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-24/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-27\n",
      "Configuration saved in my_tapelegen_model/checkpoint-27/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-27/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-27/preprocessor_config.json\n",
      "/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 672\n",
      "Saving model checkpoint to my_tapelegen_model/checkpoint-30\n",
      "Configuration saved in my_tapelegen_model/checkpoint-30/config.json\n",
      "Model weights saved in my_tapelegen_model/checkpoint-30/pytorch_model.bin\n",
      "Image processor saved in my_tapelegen_model/checkpoint-30/preprocessor_config.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=0.5591493288675944, metrics={'train_runtime': 375.8907, 'train_samples_per_second': 207.374, 'train_steps_per_second': 0.08, 'total_flos': 6.040554729553613e+18, 'train_loss': 0.5591493288675944, 'epoch': 10.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61afd345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'eval_loss': 1.0457417964935303,\n",
       "  'eval_accuracy': 0.6570841889117043,\n",
       "  'eval_runtime': 2.7143,\n",
       "  'eval_samples_per_second': 358.845,\n",
       "  'eval_steps_per_second': 0.737,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3},\n",
       " {'eval_loss': 0.8409886360168457,\n",
       "  'eval_accuracy': 0.9086242299794661,\n",
       "  'eval_runtime': 2.6239,\n",
       "  'eval_samples_per_second': 371.203,\n",
       "  'eval_steps_per_second': 0.762,\n",
       "  'epoch': 2.0,\n",
       "  'step': 6},\n",
       " {'eval_loss': 0.648750364780426,\n",
       "  'eval_accuracy': 0.9271047227926078,\n",
       "  'eval_runtime': 2.64,\n",
       "  'eval_samples_per_second': 368.946,\n",
       "  'eval_steps_per_second': 0.758,\n",
       "  'epoch': 3.0,\n",
       "  'step': 9},\n",
       " {'loss': 0.9206,\n",
       "  'learning_rate': 3.7037037037037037e-05,\n",
       "  'epoch': 3.33,\n",
       "  'step': 10},\n",
       " {'eval_loss': 0.5163537859916687,\n",
       "  'eval_accuracy': 0.9322381930184805,\n",
       "  'eval_runtime': 2.7394,\n",
       "  'eval_samples_per_second': 355.552,\n",
       "  'eval_steps_per_second': 0.73,\n",
       "  'epoch': 4.0,\n",
       "  'step': 12},\n",
       " {'eval_loss': 0.42631781101226807,\n",
       "  'eval_accuracy': 0.944558521560575,\n",
       "  'eval_runtime': 2.7254,\n",
       "  'eval_samples_per_second': 357.382,\n",
       "  'eval_steps_per_second': 0.734,\n",
       "  'epoch': 5.0,\n",
       "  'step': 15},\n",
       " {'eval_loss': 0.36801064014434814,\n",
       "  'eval_accuracy': 0.9455852156057495,\n",
       "  'eval_runtime': 2.6138,\n",
       "  'eval_samples_per_second': 372.636,\n",
       "  'eval_steps_per_second': 0.765,\n",
       "  'epoch': 6.0,\n",
       "  'step': 18},\n",
       " {'loss': 0.4515,\n",
       "  'learning_rate': 1.8518518518518518e-05,\n",
       "  'epoch': 6.67,\n",
       "  'step': 20},\n",
       " {'eval_loss': 0.3299981653690338,\n",
       "  'eval_accuracy': 0.9496919917864476,\n",
       "  'eval_runtime': 2.7869,\n",
       "  'eval_samples_per_second': 349.498,\n",
       "  'eval_steps_per_second': 0.718,\n",
       "  'epoch': 7.0,\n",
       "  'step': 21},\n",
       " {'eval_loss': 0.3060579001903534,\n",
       "  'eval_accuracy': 0.9496919917864476,\n",
       "  'eval_runtime': 2.6172,\n",
       "  'eval_samples_per_second': 372.159,\n",
       "  'eval_steps_per_second': 0.764,\n",
       "  'epoch': 8.0,\n",
       "  'step': 24},\n",
       " {'eval_loss': 0.2925540804862976,\n",
       "  'eval_accuracy': 0.9507186858316222,\n",
       "  'eval_runtime': 2.6147,\n",
       "  'eval_samples_per_second': 372.507,\n",
       "  'eval_steps_per_second': 0.765,\n",
       "  'epoch': 9.0,\n",
       "  'step': 27},\n",
       " {'loss': 0.3054, 'learning_rate': 0.0, 'epoch': 10.0, 'step': 30},\n",
       " {'eval_loss': 0.28778621554374695,\n",
       "  'eval_accuracy': 0.9537987679671458,\n",
       "  'eval_runtime': 2.6221,\n",
       "  'eval_samples_per_second': 371.456,\n",
       "  'eval_steps_per_second': 0.763,\n",
       "  'epoch': 10.0,\n",
       "  'step': 30},\n",
       " {'train_runtime': 375.8907,\n",
       "  'train_samples_per_second': 207.374,\n",
       "  'train_steps_per_second': 0.08,\n",
       "  'total_flos': 6.040554729553613e+18,\n",
       "  'train_loss': 0.5591493288675944,\n",
       "  'epoch': 10.0,\n",
       "  'step': 30}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb57bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the log history and collect the value eval_loss in a list if the key exists in the dict item\n",
    "eval_loss = [item[\"eval_loss\"] for item in trainer.state.log_history if \"eval_loss\" in item.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a82061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now collect the accuracy in a list ehich has the key eval_accuracy\n",
    "eval_accuracy = [item[\"eval_accuracy\"] for item in trainer.state.log_history if \"eval_accuracy\" in item.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "133de1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot eval loss and accuracy in the same plot with two y axis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('eval_loss', color=color)\n",
    "ax1.plot(eval_loss, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('eval_accuracy', color=color)\n",
    "ax2.plot(eval_accuracy, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d68063b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to my_best_tapelegen_model\n",
      "Configuration saved in my_best_tapelegen_model/config.json\n",
      "Model weights saved in my_best_tapelegen_model/pytorch_model.bin\n",
      "Image processor saved in my_best_tapelegen_model/preprocessor_config.json\n"
     ]
    }
   ],
   "source": [
    "# get local checkpoints of trained model\n",
    "trainer.save_model(\"my_best_tapelegen_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46a0daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: my_best_tapelegen_model/ (stored 0%)\n",
      "updating: my_best_tapelegen_model/training_args.bin (deflated 48%)\n",
      "updating: my_best_tapelegen_model/config.json (deflated 48%)\n",
      "updating: my_best_tapelegen_model/pytorch_model.bin (deflated 7%)\n",
      "updating: my_best_tapelegen_model/preprocessor_config.json (deflated 47%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r my_best_tapelegen_model.zip my_best_tapelegen_model \n",
    "bucket.upload_file('my_best_tapelegen_model.zip', 'dlr/my_best_tapelegen_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03fec177",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Preprocess is not JSON serializable\nThe format kwargs must be JSON serializable, but key 'transform' isn't.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_test_valid_dataset\u001b[39m.\u001b[39;49msave_to_disk(\u001b[39m'\u001b[39;49m\u001b[39mtrain_test_valid_dataset\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/dataset_dict.py:1226\u001b[0m, in \u001b[0;36mDatasetDict.save_to_disk\u001b[0;34m(self, dataset_dict_path, fs, max_shard_size, num_shards, num_proc, storage_options)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     json\u001b[39m.\u001b[39mdump({\u001b[39m\"\u001b[39m\u001b[39msplits\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m)}, f)\n\u001b[1;32m   1225\u001b[0m \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems():\n\u001b[0;32m-> 1226\u001b[0m     dataset\u001b[39m.\u001b[39;49msave_to_disk(\n\u001b[1;32m   1227\u001b[0m         path_join(dataset_dict_path, k),\n\u001b[1;32m   1228\u001b[0m         num_shards\u001b[39m=\u001b[39;49mnum_shards\u001b[39m.\u001b[39;49mget(k),\n\u001b[1;32m   1229\u001b[0m         max_shard_size\u001b[39m=\u001b[39;49mmax_shard_size,\n\u001b[1;32m   1230\u001b[0m         num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[1;32m   1231\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   1232\u001b[0m     )\n",
      "File \u001b[0;32m/home/ray/anaconda3/lib/python3.8/site-packages/datasets/arrow_dataset.py:1470\u001b[0m, in \u001b[0;36mDataset.save_to_disk\u001b[0;34m(self, dataset_path, fs, max_shard_size, num_shards, num_proc, storage_options)\u001b[0m\n\u001b[1;32m   1468\u001b[0m         json\u001b[39m.\u001b[39mdumps(state[\u001b[39m\"\u001b[39m\u001b[39m_format_kwargs\u001b[39m\u001b[39m\"\u001b[39m][k])\n\u001b[1;32m   1469\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1470\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1471\u001b[0m             \u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mThe format kwargs must be JSON serializable, but key \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1472\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1473\u001b[0m \u001b[39m# Get json serializable dataset info\u001b[39;00m\n\u001b[1;32m   1474\u001b[0m dataset_info \u001b[39m=\u001b[39m asdict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Preprocess is not JSON serializable\nThe format kwargs must be JSON serializable, but key 'transform' isn't."
     ]
    }
   ],
   "source": [
    "train_test_valid_dataset.save_to_disk('train_test_valid_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ba1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r train_test_valid_dataset.zip train_test_valid_dataset \n",
    "bucket.upload_file('train_test_valid_dataset.zip', 'dlr/train_test_valid_dataset.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
